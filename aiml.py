# -*- coding: utf-8 -*-
"""AIML

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N_83KKaUSZG_jx4Mi7A1FMeiwsVXnKxU
"""

!pip install -q kaggle

!mkdir ~/.kaggle

!cp kaggle.json ~/.kaggle

#############################################################################



!unzip /content/drive/MyDrive/archive.zip

from keras.models import Sequential
from keras.layers import Convolution2D,Flatten,Dense,MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator

train_datagen=ImageDataGenerator(horizontal_flip=True,rescale=1./255,zoom_range=0.2)
#rescale=1./255 means transform every pixel value from range [0,255] -> [0,1]

test_datagen=ImageDataGenerator(rescale=1./255)

x_train=train_datagen.flow_from_directory("/content/dataset/Training",target_size=(128,128),batch_size=4)

x_test=test_datagen.flow_from_directory("/content/dataset/Testing",target_size=(128,128),class_mode='categorical',batch_size=4)

model=Sequential()

#1)convolution layer
model.add(Convolution2D(32,(3,3),input_shape=(128,128,3),activation='relu'))

#1)maxpooling layer
model.add(MaxPooling2D(pool_size=(2,2)))

#2)convolution layer
model.add(Convolution2D(32,(3,3),activation='relu'))

#2)maxpooling layer
model.add(MaxPooling2D(pool_size=(2,2)))

#Flatten layer
model.add(Flatten())

model.summary()

model.add(Dense(300,activation='relu'))#hidden layer
model.add(Dense(150,activation='relu'))#hidden layer
model.add(Dense(6,activation='softmax'))#output layer

model.compile(optimizer="adam",loss="categorical_crossentropy",metrics=['accuracy'])

#training the model

model.fit_generator(x_train,
                    steps_per_epoch= len(x_train),
                    epochs = 30,
                    validation_data = x_test,
                    validation_steps = len(x_test))

model.save('garbage.h5')

import numpy as np
from keras.preprocessing import image

# testing 1

img = image.load_img('/content/dataset/Testing/plastic/plastic266.jpg',target_size =(128,128))
img

x = image.img_to_array(img)
x = np.expand_dims(x,axis = 0)
pred =np.argmax(model.predict(x))
op =['cardboard','glass','metal','paper','trash','plastic']
op[pred]

# testing 2

img = image.load_img('/content/dataset/Testing/paper/paper481.jpg',target_size =(128,128))
img

x = image.img_to_array(img)
x = np.expand_dims(x,axis = 0)
pred =np.argmax(model.predict(x))
op =['cardboard','glass','metal','paper','trash','plastic']
op[pred]

# testing 3

img = image.load_img('/content/dataset/Testing/glass/glass400.jpg',target_size =(128,128))
img

x = image.img_to_array(img)
x = np.expand_dims(x,axis = 0)
pred =np.argmax(model.predict(x))
op =['glass','metal','paper','trash','plastic']
op[pred]

# testing 4

img = image.load_img('/content/dataset/Training/trash/trash100.jpg',target_size =(128,128))
img

x = image.img_to_array(img)
x = np.expand_dims(x,axis = 0)
pred =np.argmax(model.predict(x))
op =['cardboard','glass','metal','paper','trash','plastic']
op[pred]

# testing 5

img = image.load_img('/content/dataset/Testing/metal/metal20.jpg',target_size =(128,128))
img

x = image.img_to_array(img)
x = np.expand_dims(x,axis = 0)
pred =np.argmax(model.predict(x))
op =['cardboard','glass','metal','paper','trash','plastic']
op[pred]

